<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script API documentation</title>
<meta name="description" content="Compute Directional Daily Volume USD for Top 50 Pairs" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script</code></h1>
</header>
<section id="section-intro">
<p>Compute Directional Daily Volume USD for Top 50 Pairs</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Compute Directional Daily Volume USD for Top 50 Pairs
&#34;&#34;&#34;

import datetime
import calendar
from os import path
import pandas as pd
from tqdm import tqdm
import scripts.subgraph_query as subgraph
from defi_econ.constants import UNISWAP_V3_DATA_PATH


def get_gross_volume(batch_pair_id: str, date_timestamp: int):
    &#34;&#34;&#34;
    fetch the gross daily volume by API
    &#34;&#34;&#34;
    # Variables for the query
    params_batch_pair = {&#34;batch_pair&#34;: batch_pair_id, &#34;date_timestamp&#34;: date_timestamp}

    # Query the daily aggregated info (gross volume USD)
    batch_pair_daily_query = &#34;&#34;&#34;
    query ($batch_pair: String!, $date_timestamp: Int!) 
    {
      poolDayDatas(
        where: {
          pool: $batch_pair,
          date: $date_timestamp
        })
        {
          txCount
          volumeToken0
          volumeToken1
          volumeUSD
          tvlUSD
        }
      }
  &#34;&#34;&#34;
    batch_pair_daily = subgraph.run_query_var(
        subgraph.http_v3, batch_pair_daily_query, params_batch_pair
    )
    # Query result for this pair
    batch_pair_gross_info = batch_pair_daily[&#34;data&#34;][&#34;poolDayDatas&#34;]

    return batch_pair_gross_info


def count_daily_mints(batch_pair_id: str, date_timestamp: int, end_timestamp: int):
    &#34;&#34;&#34;
    get all mints transactions and count daily mints
    &#34;&#34;&#34;
    # Iteration for counting the mints transactions within the date
    # Global variables
    mints_count = 0
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_mints_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all mints transactions
        mints_batch_query = &#34;&#34;&#34;
        query($batch_pair: String!, $last_timestamp_gt: Int!)
        {
            mints(first: 1000, 
            where: {
                pool: $batch_pair,
                timestamp_gt: $last_timestamp_gt
            }, orderBy: timestamp, orderDirection: asc)
            {
            transaction {
                id
            }
            timestamp
            amountUSD
            }
        }
        &#34;&#34;&#34;
        mints_batch = subgraph.run_query_var(
            subgraph.http_v3, mints_batch_query, params_mints_gt
        )

        # Mint transactions in this batch
        mints_txs_batch = mints_batch[&#34;data&#34;][&#34;mints&#34;]

        # Fix issue: no transaction in the next day
        if len(mints_txs_batch) == 0:
            break

        # Do loop to observe each mint transaction
        for i in range(len(mints_txs_batch)):
            # Update the last_timestamp
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(mints_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date of this batch
            if int(mints_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                mints_count = mints_count + 1

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End of the for loop, we got the transactions in this batch
    # End of the while loop, we got the transactions for all batchs

    return mints_count


def count_daily_burns(batch_pair_id: str, date_timestamp: int, end_timestamp: int):
    &#34;&#34;&#34;
    get all burns transactions and count daily burns
    &#34;&#34;&#34;
    # Iteration for counting the burns transactions within the date
    # Global variables
    burns_count = 0
    # Initialize the last timestamp
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_burns_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all burns transactions
        burns_batch_query = &#34;&#34;&#34;
      query($batch_pair: String!, $last_timestamp_gt: Int!)
      {
        burns(first: 1000, 
          where: {
            pool: $batch_pair,
            timestamp_gt: $last_timestamp_gt
          }, orderBy: timestamp, orderDirection: asc)
        {
          transaction {
            id
          }
          timestamp
          amountUSD
        }
      }
    &#34;&#34;&#34;
        burns_batch = subgraph.run_query_var(
            subgraph.http_v3, burns_batch_query, params_burns_gt
        )

        # burns transactions in this batch
        burns_txs_batch = burns_batch[&#34;data&#34;][&#34;burns&#34;]

        # Fix issue: no transaction in the next day
        if len(burns_txs_batch) == 0:
            break

        # Do loop to observe each burns transaction
        for i in range(len(burns_txs_batch)):
            # Update the last_timestamp
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(burns_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date of this batch
            if int(burns_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                burns_count = burns_count + 1

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End of the for loop, we got the transactions in this batch
    # End of the while loop, we got the transactions for all batchs

    return burns_count


def compute_daily_directional_volume(
    batch_pair_id: str, date_timestamp: int, end_timestamp: int
):
    &#34;&#34;&#34;
    manually compute the directional volume by iterating each transaction
    &#34;&#34;&#34;
    # Iteration for calculating directional daily volume USD
    # by summing swaps of token 0-&gt;1 and 1-&gt;0

    # Global variables
    swaps_count = 0
    tx_0to1_count = 0
    tx_1to0_count = 0
    volume_0to1 = 0.0
    volume_1to0 = 0.0

    # Initialize the last timestamp
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_swaps_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all transactions within the date
        swaps_batch_query = &#34;&#34;&#34;
      query($batch_pair: String!, $last_timestamp_gt: Int!)
      {
        swaps(first: 1000, 
          where: {
            pool: $batch_pair,
            timestamp_gt: $last_timestamp_gt
          }, orderBy: timestamp, orderDirection: asc)
        {
          transaction {
            id
          }
          timestamp
          amount0
          amount1
          amountUSD
        }
      }
    &#34;&#34;&#34;
        swaps_batch = subgraph.run_query_var(
            subgraph.http_v3, swaps_batch_query, params_swaps_gt
        )

        # Swap transactions in this batch
        swaps_txs_batch = swaps_batch[&#34;data&#34;][&#34;swaps&#34;]

        # Fix issue: no transaction in the next day
        if len(swaps_txs_batch) == 0:
            break

        # Do loop to observe each swap transaction
        for i in range(len(swaps_txs_batch)):
            # Update the last_timestamp no matter which type of transaction it is
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(swaps_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date
            if int(swaps_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                swaps_count = swaps_count + 1

                # For swaps: token0 to token1
                # A.K.A. SWAP token0 for token1, token0 IN, token1 OUT
                # 0IN != 0 (must), 0OUT == 0, 1IN == 0, 1OUT != 0 (must)
                # V3: 0IN -&gt; amount 0 &gt; 0, 1OUT -&gt; amount1 &lt; 0
                if (float(swaps_txs_batch[i][&#34;amount0&#34;]) &gt; 0.0) and (
                    float(swaps_txs_batch[i][&#34;amount1&#34;]) &lt; 0.0
                ):
                    tx_0to1_count = tx_0to1_count + 1
                    volume_0to1 = volume_0to1 + float(swaps_txs_batch[i][&#34;amountUSD&#34;])

                # For swaps: token1 to token0
                # A.K.A. SWAP token1 for token0, token0 OUT, token1 IN
                # 0IN == 0 (or not?), 0OUT != 0 (must), 1IN != 0 (Must), 1OUT == 0
                # V3: 0OUT -&gt; amount0&lt;0,  1IN -&gt; amount1&gt;0
                elif (float(swaps_txs_batch[i][&#34;amount1&#34;]) &gt; 0.0) and (
                    float(swaps_txs_batch[i][&#34;amount0&#34;]) &lt; 0.0
                ):
                    tx_1to0_count = tx_1to0_count + 1
                    volume_1to0 = volume_1to0 + float(swaps_txs_batch[i][&#34;amountUSD&#34;])

                # Theoretically no transactions here
                else:
                    print(
                        &#34;Invest what happens on this transaction: &#34;,
                        swaps_txs_batch[i][&#34;id&#34;],
                    )

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End the for loop (finish summing this batch)
    # End the while loop (finish summing all batch)

    return swaps_count, tx_0to1_count, volume_0to1, tx_1to0_count, volume_1to0


if __name__ == &#34;__main__&#34;:
    # Define the date we would aggregate
    day = 31
    month = 5
    year = 2022

    # Convert to datetime
    aggregate_date = datetime.datetime(year, month, day, 0, 0)
    # Convert the readable date to the unix timestamp
    date_timestamp = int(calendar.timegm(aggregate_date.timetuple()))
    # End timestamp (the next day)
    end_date = aggregate_date + datetime.timedelta(days=1)
    end_timestamp = int(calendar.timegm(end_date.timetuple()))

    # Load the dataframe from the top 50 pairs of May
    df_top50_pairs_dir_volume = pd.read_csv(
        UNISWAP_V3_DATA_PATH + &#34;/top50_pairs_avg_daily_volume_v3_MAY2022.csv&#34;
    )
    df_top50_pairs_dir_volume = df_top50_pairs_dir_volume.drop(
        columns=[
            &#34;Unnamed: 0&#34;,
            &#34;pastTotalVolumeUSD&#34;,
            &#34;pastValidDays&#34;,
            &#34;avgDailyVolumeUSD&#34;,
        ]
    )

    # Do iteration to sum up all transaction (directional) for each pair
    for index, row in tqdm(
        df_top50_pairs_dir_volume.iterrows(), total=df_top50_pairs_dir_volume.shape[0]
    ):
        # Pool id for this batch
        batch_pair_id = row[&#34;id&#34;]

        # Get the daily gross volume from subgraph API
        batch_pair_info = get_gross_volume(batch_pair_id, date_timestamp)
        # Store values for the daily aggregated data
        df_top50_pairs_dir_volume.loc[index, &#34;dailyTxns&#34;] = batch_pair_info[0][
            &#34;txCount&#34;
        ]
        df_top50_pairs_dir_volume.loc[index, &#34;dailyGrossVolumeUSD&#34;] = batch_pair_info[
            0
        ][&#34;volumeUSD&#34;]
        df_top50_pairs_dir_volume.loc[index, &#34;dailySwapVolumeToken0&#34;] = batch_pair_info[
            0
        ][&#34;volumeToken0&#34;]
        df_top50_pairs_dir_volume.loc[index, &#34;dailySwapVolumeToken1&#34;] = batch_pair_info[
            0
        ][&#34;volumeToken1&#34;]
        df_top50_pairs_dir_volume.loc[index, &#34;tvlUSD&#34;] = batch_pair_info[0][&#34;tvlUSD&#34;]

        # Get the daily count for the mints transactions
        mints_count = count_daily_mints(batch_pair_id, date_timestamp, end_timestamp)
        # Store the values to the dataframe for this pair
        df_top50_pairs_dir_volume.loc[index, &#34;mintsCount&#34;] = mints_count

        # Get the daily count for the burns transactions
        burns_count = count_daily_burns(batch_pair_id, date_timestamp, end_timestamp)
        # Store the values to the dataframe for this pair
        df_top50_pairs_dir_volume.loc[index, &#34;burnsCount&#34;] = burns_count

        # Compute the daily directional volume of swaps
        (
            swaps_count,
            tx_0to1_count,
            volume_0to1,
            tx_1to0_count,
            volume_1to0,
        ) = compute_daily_directional_volume(
            batch_pair_id, date_timestamp, end_timestamp
        )
        # Store the values to the dataframe for this pair
        df_top50_pairs_dir_volume.loc[index, &#34;swapsCount&#34;] = swaps_count
        df_top50_pairs_dir_volume.loc[index, &#34;token0To1Txs&#34;] = tx_0to1_count
        df_top50_pairs_dir_volume.loc[index, &#34;token0To1VolumeUSD&#34;] = volume_0to1
        df_top50_pairs_dir_volume.loc[index, &#34;token1To0Txs&#34;] = tx_1to0_count
        df_top50_pairs_dir_volume.loc[index, &#34;token1To0VolumeUSD&#34;] = volume_1to0
        df_top50_pairs_dir_volume.loc[index, &#34;GrossVolumeUSD&#34;] = (
            volume_0to1 + volume_1to0
        )
    # End of the for loop

    # Delete the data of directly fected by daily aggregated API because the error is small
    df_top50_pairs_dir_volume = df_top50_pairs_dir_volume.drop(
        columns=[&#34;dailyGrossVolumeUSD&#34;]
    )

    # Data file contains the defined date for the aggregation
    file_date = aggregate_date.date().strftime(&#34;%Y%m%d&#34;)

    # Define the file name
    file_name = path.join(
        UNISWAP_V3_DATA_PATH, &#34;top50_pairs_directional_volume_v3_&#34; + file_date + &#34;.csv&#34;
    )
    # Write dataframe to csv
    df_top50_pairs_dir_volume.to_csv(file_name)
    print(&#34;-------------------------&#34;)
    print(&#34;Complete write the file: &#34;, file_name)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.compute_daily_directional_volume"><code class="name flex">
<span>def <span class="ident">compute_daily_directional_volume</span></span>(<span>batch_pair_id: str, date_timestamp: int, end_timestamp: int)</span>
</code></dt>
<dd>
<div class="desc"><p>manually compute the directional volume by iterating each transaction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_daily_directional_volume(
    batch_pair_id: str, date_timestamp: int, end_timestamp: int
):
    &#34;&#34;&#34;
    manually compute the directional volume by iterating each transaction
    &#34;&#34;&#34;
    # Iteration for calculating directional daily volume USD
    # by summing swaps of token 0-&gt;1 and 1-&gt;0

    # Global variables
    swaps_count = 0
    tx_0to1_count = 0
    tx_1to0_count = 0
    volume_0to1 = 0.0
    volume_1to0 = 0.0

    # Initialize the last timestamp
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_swaps_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all transactions within the date
        swaps_batch_query = &#34;&#34;&#34;
      query($batch_pair: String!, $last_timestamp_gt: Int!)
      {
        swaps(first: 1000, 
          where: {
            pool: $batch_pair,
            timestamp_gt: $last_timestamp_gt
          }, orderBy: timestamp, orderDirection: asc)
        {
          transaction {
            id
          }
          timestamp
          amount0
          amount1
          amountUSD
        }
      }
    &#34;&#34;&#34;
        swaps_batch = subgraph.run_query_var(
            subgraph.http_v3, swaps_batch_query, params_swaps_gt
        )

        # Swap transactions in this batch
        swaps_txs_batch = swaps_batch[&#34;data&#34;][&#34;swaps&#34;]

        # Fix issue: no transaction in the next day
        if len(swaps_txs_batch) == 0:
            break

        # Do loop to observe each swap transaction
        for i in range(len(swaps_txs_batch)):
            # Update the last_timestamp no matter which type of transaction it is
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(swaps_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date
            if int(swaps_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                swaps_count = swaps_count + 1

                # For swaps: token0 to token1
                # A.K.A. SWAP token0 for token1, token0 IN, token1 OUT
                # 0IN != 0 (must), 0OUT == 0, 1IN == 0, 1OUT != 0 (must)
                # V3: 0IN -&gt; amount 0 &gt; 0, 1OUT -&gt; amount1 &lt; 0
                if (float(swaps_txs_batch[i][&#34;amount0&#34;]) &gt; 0.0) and (
                    float(swaps_txs_batch[i][&#34;amount1&#34;]) &lt; 0.0
                ):
                    tx_0to1_count = tx_0to1_count + 1
                    volume_0to1 = volume_0to1 + float(swaps_txs_batch[i][&#34;amountUSD&#34;])

                # For swaps: token1 to token0
                # A.K.A. SWAP token1 for token0, token0 OUT, token1 IN
                # 0IN == 0 (or not?), 0OUT != 0 (must), 1IN != 0 (Must), 1OUT == 0
                # V3: 0OUT -&gt; amount0&lt;0,  1IN -&gt; amount1&gt;0
                elif (float(swaps_txs_batch[i][&#34;amount1&#34;]) &gt; 0.0) and (
                    float(swaps_txs_batch[i][&#34;amount0&#34;]) &lt; 0.0
                ):
                    tx_1to0_count = tx_1to0_count + 1
                    volume_1to0 = volume_1to0 + float(swaps_txs_batch[i][&#34;amountUSD&#34;])

                # Theoretically no transactions here
                else:
                    print(
                        &#34;Invest what happens on this transaction: &#34;,
                        swaps_txs_batch[i][&#34;id&#34;],
                    )

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End the for loop (finish summing this batch)
    # End the while loop (finish summing all batch)

    return swaps_count, tx_0to1_count, volume_0to1, tx_1to0_count, volume_1to0</code></pre>
</details>
</dd>
<dt id="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_burns"><code class="name flex">
<span>def <span class="ident">count_daily_burns</span></span>(<span>batch_pair_id: str, date_timestamp: int, end_timestamp: int)</span>
</code></dt>
<dd>
<div class="desc"><p>get all burns transactions and count daily burns</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_daily_burns(batch_pair_id: str, date_timestamp: int, end_timestamp: int):
    &#34;&#34;&#34;
    get all burns transactions and count daily burns
    &#34;&#34;&#34;
    # Iteration for counting the burns transactions within the date
    # Global variables
    burns_count = 0
    # Initialize the last timestamp
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_burns_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all burns transactions
        burns_batch_query = &#34;&#34;&#34;
      query($batch_pair: String!, $last_timestamp_gt: Int!)
      {
        burns(first: 1000, 
          where: {
            pool: $batch_pair,
            timestamp_gt: $last_timestamp_gt
          }, orderBy: timestamp, orderDirection: asc)
        {
          transaction {
            id
          }
          timestamp
          amountUSD
        }
      }
    &#34;&#34;&#34;
        burns_batch = subgraph.run_query_var(
            subgraph.http_v3, burns_batch_query, params_burns_gt
        )

        # burns transactions in this batch
        burns_txs_batch = burns_batch[&#34;data&#34;][&#34;burns&#34;]

        # Fix issue: no transaction in the next day
        if len(burns_txs_batch) == 0:
            break

        # Do loop to observe each burns transaction
        for i in range(len(burns_txs_batch)):
            # Update the last_timestamp
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(burns_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date of this batch
            if int(burns_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                burns_count = burns_count + 1

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End of the for loop, we got the transactions in this batch
    # End of the while loop, we got the transactions for all batchs

    return burns_count</code></pre>
</details>
</dd>
<dt id="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_mints"><code class="name flex">
<span>def <span class="ident">count_daily_mints</span></span>(<span>batch_pair_id: str, date_timestamp: int, end_timestamp: int)</span>
</code></dt>
<dd>
<div class="desc"><p>get all mints transactions and count daily mints</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_daily_mints(batch_pair_id: str, date_timestamp: int, end_timestamp: int):
    &#34;&#34;&#34;
    get all mints transactions and count daily mints
    &#34;&#34;&#34;
    # Iteration for counting the mints transactions within the date
    # Global variables
    mints_count = 0
    last_timestamp_gt = date_timestamp - 1

    # If the last timestamp for the previous batch is earlier than the end timestamp
    while last_timestamp_gt &lt; end_timestamp:
        params_mints_gt = {
            &#34;batch_pair&#34;: batch_pair_id,
            &#34;last_timestamp_gt&#34;: last_timestamp_gt,
        }
        # Get all mints transactions
        mints_batch_query = &#34;&#34;&#34;
        query($batch_pair: String!, $last_timestamp_gt: Int!)
        {
            mints(first: 1000, 
            where: {
                pool: $batch_pair,
                timestamp_gt: $last_timestamp_gt
            }, orderBy: timestamp, orderDirection: asc)
            {
            transaction {
                id
            }
            timestamp
            amountUSD
            }
        }
        &#34;&#34;&#34;
        mints_batch = subgraph.run_query_var(
            subgraph.http_v3, mints_batch_query, params_mints_gt
        )

        # Mint transactions in this batch
        mints_txs_batch = mints_batch[&#34;data&#34;][&#34;mints&#34;]

        # Fix issue: no transaction in the next day
        if len(mints_txs_batch) == 0:
            break

        # Do loop to observe each mint transaction
        for i in range(len(mints_txs_batch)):
            # Update the last_timestamp
            # last_ts_gt &gt;= end_ts after the executing of loop break
            last_timestamp_gt = int(mints_txs_batch[i][&#34;timestamp&#34;])

            # Only count transactions within the given date of this batch
            if int(mints_txs_batch[i][&#34;timestamp&#34;]) &lt; end_timestamp:
                # Count++ for the valid swap
                mints_count = mints_count + 1

            # Stop loop when the timestamp exceed the end timestamp
            else:
                break

        # End of the for loop, we got the transactions in this batch
    # End of the while loop, we got the transactions for all batchs

    return mints_count</code></pre>
</details>
</dd>
<dt id="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.get_gross_volume"><code class="name flex">
<span>def <span class="ident">get_gross_volume</span></span>(<span>batch_pair_id: str, date_timestamp: int)</span>
</code></dt>
<dd>
<div class="desc"><p>fetch the gross daily volume by API</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_gross_volume(batch_pair_id: str, date_timestamp: int):
    &#34;&#34;&#34;
    fetch the gross daily volume by API
    &#34;&#34;&#34;
    # Variables for the query
    params_batch_pair = {&#34;batch_pair&#34;: batch_pair_id, &#34;date_timestamp&#34;: date_timestamp}

    # Query the daily aggregated info (gross volume USD)
    batch_pair_daily_query = &#34;&#34;&#34;
    query ($batch_pair: String!, $date_timestamp: Int!) 
    {
      poolDayDatas(
        where: {
          pool: $batch_pair,
          date: $date_timestamp
        })
        {
          txCount
          volumeToken0
          volumeToken1
          volumeUSD
          tvlUSD
        }
      }
  &#34;&#34;&#34;
    batch_pair_daily = subgraph.run_query_var(
        subgraph.http_v3, batch_pair_daily_query, params_batch_pair
    )
    # Query result for this pair
    batch_pair_gross_info = batch_pair_daily[&#34;data&#34;][&#34;poolDayDatas&#34;]

    return batch_pair_gross_info</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="scripts.fetch_scripts_v3" href="index.html">scripts.fetch_scripts_v3</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.compute_daily_directional_volume" href="#scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.compute_daily_directional_volume">compute_daily_directional_volume</a></code></li>
<li><code><a title="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_burns" href="#scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_burns">count_daily_burns</a></code></li>
<li><code><a title="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_mints" href="#scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.count_daily_mints">count_daily_mints</a></code></li>
<li><code><a title="scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.get_gross_volume" href="#scripts.fetch_scripts_v3.top50_pair_directional_volume_v3_script.get_gross_volume">get_gross_volume</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>