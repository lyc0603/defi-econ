{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniswap Overview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import jupyter_black\n",
    "from ast import literal_eval\n",
    "\n",
    "from environ.constants import (\n",
    "    SAMPLE_PERIOD,\n",
    "    UNISWAP_V2_DATA_PATH,\n",
    "    UNISWAP_V3_DATA_PATH,\n",
    "    BETWEENNESS_DATA_PATH,\n",
    ")\n",
    "\n",
    "jupyter_black.load()\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unqiue Pair Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique pairs in v2: 122458\n",
      "Number of unique pairs in v3: 8436\n"
     ]
    }
   ],
   "source": [
    "for dex_path, idx in [\n",
    "    (UNISWAP_V2_DATA_PATH, \"v2\"),\n",
    "    (UNISWAP_V3_DATA_PATH, \"v3\"),\n",
    "]:\n",
    "    # load in all folders in constants.UNISWAP_V2_DATA_PATH\n",
    "    folder_lst = glob.glob(str(dex_path / \"swap\" / \"*\"))\n",
    "\n",
    "    # load in all files in each folder\n",
    "    file_lst = []\n",
    "    for folder in folder_lst:\n",
    "        file_lst.extend(glob.glob(os.path.join(folder, \"*.csv\")))\n",
    "\n",
    "    # only keep files that are in the sample period\n",
    "    file_lst = [\n",
    "        file\n",
    "        for file in file_lst\n",
    "        if (\n",
    "            SAMPLE_PERIOD[0]\n",
    "            <= file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "            <= SAMPLE_PERIOD[1]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Iterate through all files and get the unique list of pool, token0_id, token1_id\n",
    "    unique_pool_lst = []\n",
    "    for file in file_lst:\n",
    "        df = pd.read_csv(file, usecols=[\"pool\", \"token0_id\", \"token1_id\"])\n",
    "        # drop duplicates\n",
    "        df = df.drop_duplicates()\n",
    "        # append to the list\n",
    "        unique_pool_lst.append(df)\n",
    "\n",
    "    # concat all the dataframes\n",
    "    unique_pool_df = pd.concat(unique_pool_lst, ignore_index=True)\n",
    "    # drop duplicates\n",
    "    unique_pool_df = unique_pool_df.drop_duplicates()\n",
    "\n",
    "    # print out the number of unique pools\n",
    "    print(f\"Number of unique pairs in {idx}: {unique_pool_df.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total swap number (Atomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting swaps: 100%|██████████| 975/975 [05:42<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of swaps of v2: 92649419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting swaps: 100%|██████████| 610/610 [01:41<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of swaps of v3: 23613266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dex_path, idx in [\n",
    "    (UNISWAP_V2_DATA_PATH, \"v2\"),\n",
    "    (UNISWAP_V3_DATA_PATH, \"v3\"),\n",
    "]:\n",
    "    # load in all folders in constants.UNISWAP_V2_DATA_PATH\n",
    "    folder_lst = glob.glob(str(dex_path / \"swap\" / \"*\"))\n",
    "\n",
    "    # load in all files in each folder\n",
    "    file_lst = []\n",
    "    for folder in folder_lst:\n",
    "        file_lst.extend(glob.glob(os.path.join(folder, \"*.csv\")))\n",
    "\n",
    "    # only keep files that are in the sample period\n",
    "    file_lst = [\n",
    "        file\n",
    "        for file in file_lst\n",
    "        if (\n",
    "            SAMPLE_PERIOD[0]\n",
    "            <= file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "            <= SAMPLE_PERIOD[1]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Iterate through all files and get the number of swaps\n",
    "    swap_count = 0\n",
    "    for file in tqdm(file_lst, desc=\"Counting swaps\"):\n",
    "        swap_count += pd.read_csv(file).shape[0]\n",
    "\n",
    "    print(f\"Total number of swaps of {idx}: {swap_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betweenness Trtades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting transactions: 100%|██████████| 944/944 [01:54<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of betwenness transactions of v2: 2121236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting transactions: 100%|██████████| 607/607 [01:01<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of betwenness transactions of v3: 1180697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dex in [\"v2\", \"v3\"]:\n",
    "    # list of all files in the betweenness folder\n",
    "    file_lst = glob.glob(str(BETWEENNESS_DATA_PATH / \"swap_route\" / \"*\"))\n",
    "\n",
    "    # only keep files that are in the sample period\n",
    "    file_lst = [\n",
    "        file\n",
    "        for file in file_lst\n",
    "        if (\n",
    "            (\n",
    "                SAMPLE_PERIOD[0]\n",
    "                <= file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "                <= SAMPLE_PERIOD[1]\n",
    "            )\n",
    "            & (file.split(\"/\")[-1].split(\"_\")[-2] == dex)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Iterate through all files and get the number of transactions\n",
    "    tx_count = 0\n",
    "    for file in tqdm(file_lst, desc=\"Counting transactions\"):\n",
    "        # load in the dataframe\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # remove the row with label as Error\n",
    "        df = df[df[\"intermediary\"] != \"Error\"]\n",
    "\n",
    "        # convert the intermediary column to a list\n",
    "        df[\"intermediary\"] = df[\"intermediary\"].apply(literal_eval)\n",
    "\n",
    "        # sum up the length of the intermediary column\n",
    "        tx_count += df[\"intermediary\"].apply(len).sum()\n",
    "\n",
    "    print(f\"Total number of betwenness transactions of {dex}: {tx_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3301933"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.028400625703767293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of betweenness swap\n",
    "2121236 + 1180697\n",
    "\n",
    "# Percentage of swaps that are betweenness in terms of number of swaps\n",
    "(2121236 + 1180697) / (92649419 + 23613266)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Transactions (Full-length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting transactions: 100%|██████████| 944/944 [00:33<00:00, 28.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transactions of v2: 18635768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting transactions: 100%|██████████| 607/607 [00:18<00:00, 32.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transactions of v3: 9973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dex in [\"v2\", \"v3\"]:\n",
    "    # list of all files in the betweenness folder\n",
    "    file_lst = glob.glob(str(BETWEENNESS_DATA_PATH / \"swap_route\" / \"*\"))\n",
    "\n",
    "    # only keep files that are in the sample period\n",
    "    file_lst = [\n",
    "        file\n",
    "        for file in file_lst\n",
    "        if (\n",
    "            (\n",
    "                SAMPLE_PERIOD[0]\n",
    "                <= file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "                <= SAMPLE_PERIOD[1]\n",
    "            )\n",
    "            & (file.split(\"/\")[-1].split(\"_\")[-2] == dex)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Iterate through all files and get the number of transactions\n",
    "    tx_count = 0\n",
    "    for file in tqdm(file_lst, desc=\"Counting transactions\"):\n",
    "        tx_count += pd.read_csv(file).shape[0]\n",
    "\n",
    "    print(f\"Total number of transactions of {dex}: {tx_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 50 pools: Swap, mint, burn number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mints of v2: 515288.0\n",
      "Total number of burns of v2: 309294.0\n",
      "Total number of swaps of v2: 29413825.0\n",
      "Total number of mints of v3: 361641.0\n",
      "Total number of burns of v3: 403640.0\n",
      "Total number of swaps of v3: 13686873.0\n"
     ]
    }
   ],
   "source": [
    "for dex_path, idx in [\n",
    "    (UNISWAP_V2_DATA_PATH, \"v2\"),\n",
    "    (UNISWAP_V3_DATA_PATH, \"v3\"),\n",
    "]:\n",
    "    # list of all files in the directional_volume folder\n",
    "    file_lst = glob.glob(str(dex_path / \"directional_volume\" / \"*\"))\n",
    "\n",
    "    # only keep files that are in the sample period\n",
    "    file_lst = [\n",
    "        file\n",
    "        for file in file_lst\n",
    "        if (\n",
    "            SAMPLE_PERIOD[0]\n",
    "            <= file.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "            <= SAMPLE_PERIOD[1]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Iterate through all files and get the number of transactions\n",
    "    mintsCount = 0\n",
    "    burnsCount = 0\n",
    "    swapsCount = 0\n",
    "    for file in file_lst:\n",
    "        # load in the file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # sum up the number of mints, burns, and swaps\n",
    "        mintsCount += df[\"mintsCount\"].sum()\n",
    "        burnsCount += df[\"burnsCount\"].sum()\n",
    "        swapsCount += df[\"swapsCount\"].sum()\n",
    "\n",
    "    print(f\"Total number of mints of {idx}: {mintsCount}\")\n",
    "    print(f\"Total number of burns of {idx}: {burnsCount}\")\n",
    "    print(f\"Total number of swaps of {idx}: {swapsCount}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
